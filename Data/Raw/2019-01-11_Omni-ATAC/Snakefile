import pandas as pd
import os.path as path
import numpy as np

# ==============================================================================
# Configuration
# ==============================================================================
CONFIG = pd.read_csv('config.tsv', index_col=False, sep='\t')

FASTQ_DIR = 'FASTQs'
REPORT_DIR = 'Reports'
TRIM_DIR = 'Trimmed'
ALIGN_DIR = 'Aligned'
PEAKS_DIR = 'Peaks'

PIPELINE_DIR = '/mnt/work1/users/lupiengroup/CommonScripts/atac-seq-pipeline/src'
BWT2_IDX = '/mnt/work1/data/genomes/human/hg38/iGenomes/Sequence/Bowtie2Index/genome'

CONDITIONS = np.unique(CONFIG['Condition'])
REPLICATES = np.unique(CONFIG['Replicate'])
SAMPLES = [c + '_Rep' +
           str(r) for (c, r) in zip(CONFIG['Condition'], CONFIG['Replicate'])]

wildcard_constraints:
    condition = '[A-Za-z0-9-]+',
    sample = '[A-Za-z0-9-_]+_Rep[1-3]'


# ==============================================================================
# Meta Rules
# ==============================================================================
rule all_trim:
    input:
        expand(
            path.join(TRIM_DIR, '{sample}.trimmed.fastq.gz'),
            sample=SAMPLES
        )

rule all_align:
    input:
        expand(
            path.join(ALIGN_DIR, '{sample}.sorted.bam'),
            sample=SAMPLES
        )

rule all_postalign:
    input:
        expand(
            path.join(ALIGN_DIR, '{sample}.sorted.filtered.bam'),
            sample=SAMPLES
        ),
        expand(
            path.join(ALIGN_DIR, '{sample}.sorted.filtered.dedup.bam'),
            sample=SAMPLES
        ),
        expand(
            path.join(REPORT_DIR, '{sample}.duplication.txt'),
            sample=SAMPLES
        ),
        expand(
            path.join(ALIGN_DIR, '{sample}.25M.tagAlign.gz'),
            sample=SAMPLES
        ),
        expand(
            path.join(ALIGN_DIR, '{condition}_Rep0.tagAlign.gz'),
            condition=CONDITIONS
        ),
        expand(
            path.join(ALIGN_DIR, '{condition}_Rep0.{pr}.tagAlign.gz'),
            condition=CONDITIONS,
            pr=['pr1', 'pr2']
        ),
        expand(
            path.join(ALIGN_DIR, '{condition}_Rep{r}.{pr}.tagAlign.gz'),
            condition=CONDITIONS,
            r=REPLICATES,
            pr=['pr1', 'pr2']
        ),


# ==============================================================================
# Rules
# ==============================================================================
# Trimming
# -------------------------------------
rule detect_adapter:
    input:
        script = path.join(PIPELINE_DIR, 'detect_adapter.py'),
        fastq = path.join(FASTQ_DIR, '{sample}.fastq.gz')
    output:
        path.join(REPORT_DIR, '{sample}.adapter.txt')
    shell:
        'python {input.script} {input.fastq} > {output}'

rule trim:
    input:
        path.join(FASTQ_DIR, '{sample}.fastq.gz')
    output:
        fq = path.join(TRIM_DIR, '{sample}.trimmed.fastq.gz'),
        rpt = path.join(REPORT_DIR, '{sample}.trim.txt')
    params:
        '-m 5 -e 0.2 -a CTGTCTCTTATA'
    shell:
        'cutadapt {params} {input} 2> {output.rpt} | gzip -nc > {output.fq}'

# Alignment
# -------------------------------------
rule align:
    input:
        path.join(TRIM_DIR, '{sample}.trimmed.fastq.gz')
    output:
        bam = path.join(ALIGN_DIR, '{sample}.bam'),
        rpt = path.join(REPORT_DIR, '{sample}.align.txt')
    params:
        '-k 4 --local -x {bwt2_idx} --threads 4'.format(bwt2_idx=BWT2_IDX)
    shell:
        'bowtie2 {params} -U {input} 2> {output.rpt} | samtools view -u > {output.bam}'

# Post-alignment filtering
# -------------------------------------
# Remove unmapped, non-primary, or failing alignments
rule filter_alignments:
    input:
        script = path.join(PIPELINE_DIR, 'assign_multimappers.py'),
        bam = path.join(ALIGN_DIR, '{sample}.sorted.bam')
    output:
        path.join(ALIGN_DIR, '{sample}.sorted.filtered.bam')
    params:
        '-k 4'
    shell:
        'sambamba view -h {input.bam} | {input.script} {params} | samtools view -F 1804 -Su /dev/stdin | sambamba sort /dev/stdin -o {output}'

# mark duplicates and get duplication stats
rule markdup:
    input:
        path.join(ALIGN_DIR, '{sample}.sorted.filtered.bam')
    output:
        path.join(REPORT_DIR, '{sample}.duplication.txt')
    run:
        commands = [
            'sambamba markdup {input} {wildcards.sample}.markdup.bam',
            'sambamba flagstat {wildcards.sample}.markdup.bam > {output}',
            'rm {wildcards.sample}.markdup.bam'
        ]
        command_str = '; '.join(commands)
        shell(command_str)

# remove duplicates
rule dedup:
    input:
        path.join(ALIGN_DIR, '{sample}.sorted.filtered.bam')
    output:
        path.join(ALIGN_DIR, '{sample}.sorted.filtered.dedup.bam')
    shell:
        'sambamba markdup -r {input} {output}'

# create tagAlign files
rule tagalign:
    input:
        path.join(ALIGN_DIR, '{sample}.bam')
    output:
        path.join(ALIGN_DIR, '{sample}.tagAlign.gz')
    shell:
        'bedtools bamtobed -i {input} | awk -v FS="\t" -v OFS="\t" \'{{$4="N"; $5="1000"; print $0}}\' | gzip -nc  > {output}'

# subsample tagAlign files
rule subsample_tagalign:
    input:
        path.join(ALIGN_DIR, '{sample}.tagAlign.gz')
    output:
        path.join(ALIGN_DIR, '{sample}.25M.tagAlign.gz')
    shell:
        'zcat {input} | grep -v "chrM" | shuf -n 25000000 --random-source {input} | gzip -nc > {output}'

# generate pooled data
rule gen_pool:
    input:
        path.join(ALIGN_DIR, '{condition}_Rep1.tagAlign.gz'),
        path.join(ALIGN_DIR, '{condition}_Rep2.tagAlign.gz')
    output:
        path.join(ALIGN_DIR, '{condition}_Rep0.tagAlign.gz')
    shell:
        'zcat {input} | gzip -nc > {output}'

# generate pseudo-replicates
rule gen_pseudo:
    input:
        path.join(ALIGN_DIR, '{sample}.tagAlign.gz')
    output:
        path.join(ALIGN_DIR, '{sample}.pr1.tagAlign.gz'),
        path.join(ALIGN_DIR, '{sample}.pr2.tagAlign.gz')
    params:
        prefix = path.join(ALIGN_DIR, '{sample}.pseudoreps')
    run:
        commands = [
            'nlines=$(zcat {input} | wc -l)',
            'nlines=$(( ($nlines + 1) / 2 ))',
            'zcat {input} | shuf --random-source {input} | split -d -l $nlines - {params.prefix}',
            'gzip -nc {params.prefix}00 > {output[0]}',
            'gzip -nc {params.prefix}01 > {output[1]}',
            'rm {params.prefix}00',
            'rm {params.prefix}01'
        ]
        command_str = '; '.join(commands)
        shell(command_str)

# generate pooled pseudo-replicates
rule gen_pool_pseudo:
    input:
        r1p1 = path.join(ALIGN_DIR, '{condition}_Rep1.pr1.tagAlign.gz'),
        r1p2 = path.join(ALIGN_DIR, '{condition}_Rep1.pr2.tagAlign.gz'),
        r2p1 = path.join(ALIGN_DIR, '{condition}_Rep2.pr1.tagAlign.gz'),
        r2p2 = path.join(ALIGN_DIR, '{condition}_Rep2.pr2.tagAlign.gz')
    output:
        pr1 = path.join(ALIGN_DIR, '{condition}_Rep0.pr1.tagAlign.gz'),
        pr2 = path.join(ALIGN_DIR, '{condition}_Rep0.pr2.tagAlign.gz')
    run:
        commands = [
            'zcat {input.r1p1} {input.r2p1} | gzip -nc > {output.pr1}',
            'zcat {input.r1p2} {input.r2p2} | gzip -nc > {output.pr2}',
        ]
        command_str = '; '.join(commands)
        shell(command_str)

# Call peaks
# -------------------------------------
rule call_peaks:
    input:
        'infile'
    output:
        'outfile'
    shell:
        'command'


# Miscellaneous
# -------------------------------------
rule sort:
    input:
        '{file}.bam'
    output:
        '{file}.sorted.bam',
        '{file}.sorted.bam.bai'
    shell:
        'sambamba sort {input} -o {output[0]}'
