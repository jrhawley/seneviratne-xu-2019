import pandas as pd
import os.path as path
import numpy as np

# ==============================================================================
# Configuration
# ==============================================================================
CONFIG = pd.read_csv('config.tsv', index_col=False, sep='\t')

FASTQ_DIR = 'FASTQs'
REPORT_DIR = 'Reports'
TRIM_DIR = 'Trimmed'
ALIGN_DIR = 'Aligned'
PEAKS_DIR = 'Peaks'

PIPELINE_DIR = '../../External/atac-seq-pipeline/src'
BWT2_IDX = '../../External/Bowtie2Index/genome'
CHR_SIZES = '../../External/hg38.chrom.sizes'

CONDITIONS = np.unique(CONFIG['Condition'])
REPLICATES = np.unique(CONFIG['Replicate'])
SAMPLES = [c + '_Rep' +
           str(r) for (c, r) in zip(CONFIG['Condition'], CONFIG['Replicate'])]

wildcard_constraints:
    condition = '[A-Za-z0-9-]+',
    sample = '[A-Za-z0-9-_]+_Rep[1-3]'


# ==============================================================================
# Meta Rules
# ==============================================================================
rule all_trim:
    input:
        expand(
            path.join(TRIM_DIR, '{sample}.trimmed.fastq.gz'),
            sample=SAMPLES
        )

rule all_align:
    input:
        expand(
            path.join(ALIGN_DIR, '{sample}.sorted.bam'),
            sample=SAMPLES
        )

rule all_postalign:
    input:
        expand(
            path.join(ALIGN_DIR, '{sample}.sorted.filtered.bam'),
            sample=SAMPLES
        ),
        expand(
            path.join(ALIGN_DIR, '{sample}.sorted.filtered.dedup.bam'),
            sample=SAMPLES
        ),
        expand(
            path.join(REPORT_DIR, '{sample}.duplication.txt'),
            sample=SAMPLES
        ),
        expand(
            path.join(ALIGN_DIR, '{sample}.25M.tagAlign.gz'),
            sample=SAMPLES
        ),
        expand(
            path.join(ALIGN_DIR, '{condition}_Rep0.tagAlign.gz'),
            condition=CONDITIONS
        ),
        expand(
            path.join(ALIGN_DIR, '{condition}_Rep0.{pr}.tagAlign.gz'),
            condition=CONDITIONS,
            pr=['pr1', 'pr2']
        ),
        expand(
            path.join(ALIGN_DIR, '{condition}_Rep{r}.{pr}.tagAlign.gz'),
            condition=CONDITIONS,
            r=REPLICATES,
            pr=['pr1', 'pr2']
        )

rule all_peaks:
    input:
        expand(
            path.join(PEAKS_DIR, '{sample}_peaks.narrowPeak.gz'),
            sample=SAMPLES
        ),
        expand(
            path.join(PEAKS_DIR, '{sample}.{type}.signal.sorted.bedGraph'),
            sample=SAMPLES,
            type=['fc', 'pval']
        ),


# ==============================================================================
# Rules
# ==============================================================================
# Trimming
# -------------------------------------
rule detect_adapter:
    input:
        script = path.join(PIPELINE_DIR, 'detect_adapter.py'),
        fastq = path.join(FASTQ_DIR, '{sample}.fastq.gz')
    output:
        path.join(REPORT_DIR, '{sample}.adapter.txt')
    shell:
        'python {input.script} {input.fastq} > {output}'

rule trim:
    input:
        path.join(FASTQ_DIR, '{sample}.fastq.gz')
    output:
        fq = path.join(TRIM_DIR, '{sample}.trimmed.fastq.gz'),
        rpt = path.join(REPORT_DIR, '{sample}.trim.txt')
    params:
        '-m 5 -e 0.2 -a CTGTCTCTTATA'
    shell:
        'cutadapt {params} {input} 2> {output.rpt} | gzip -nc > {output.fq}'

# Alignment
# -------------------------------------
rule align:
    input:
        path.join(TRIM_DIR, '{sample}.trimmed.fastq.gz')
    output:
        bam = path.join(ALIGN_DIR, '{sample}.bam'),
        rpt = path.join(REPORT_DIR, '{sample}.align.txt')
    params:
        '-k 4 --local -x {bwt2_idx} --threads 4'.format(bwt2_idx=BWT2_IDX)
    shell:
        'bowtie2 {params} -U {input} 2> {output.rpt} | samtools view -u > {output.bam}'

# Post-alignment filtering
# -------------------------------------
# Remove unmapped, non-primary, or failing alignments
rule filter_alignments:
    input:
        script = path.join(PIPELINE_DIR, 'assign_multimappers.py'),
        bam = path.join(ALIGN_DIR, '{sample}.sorted.bam')
    output:
        path.join(ALIGN_DIR, '{sample}.sorted.filtered.bam')
    params:
        '-k 4'
    shell:
        'sambamba view -h {input.bam} | {input.script} {params} | samtools view -F 1804 -Su /dev/stdin | sambamba sort /dev/stdin -o {output}'

# mark duplicates and get duplication stats
rule markdup:
    input:
        path.join(ALIGN_DIR, '{sample}.sorted.filtered.bam')
    output:
        path.join(REPORT_DIR, '{sample}.duplication.txt')
    run:
        commands = [
            'sambamba markdup {input} {wildcards.sample}.markdup.bam',
            'sambamba flagstat {wildcards.sample}.markdup.bam > {output}',
            'rm {wildcards.sample}.markdup.bam'
        ]
        command_str = '; '.join(commands)
        shell(command_str)

# remove duplicates
rule dedup:
    input:
        path.join(ALIGN_DIR, '{sample}.sorted.filtered.bam')
    output:
        path.join(ALIGN_DIR, '{sample}.sorted.filtered.dedup.bam')
    shell:
        'sambamba markdup -r {input} {output}'

# create tagAlign files
rule tagalign:
    input:
        path.join(ALIGN_DIR, '{sample}.bam')
    output:
        path.join(ALIGN_DIR, '{sample}.tagAlign.gz')
    shell:
        'bedtools bamtobed -i {input} | awk -v FS="\t" -v OFS="\t" \'{{$4="N"; $5="1000"; print $0}}\' | gzip -nc  > {output}'

# subsample tagAlign files
rule subsample_tagalign:
    input:
        path.join(ALIGN_DIR, '{sample}.tagAlign.gz')
    output:
        path.join(ALIGN_DIR, '{sample}.25M.tagAlign.gz')
    shell:
        'zcat {input} | grep -v "chrM" | shuf -n 25000000 --random-source {input} | gzip -nc > {output}'

# generate pooled data
rule gen_pool:
    input:
        path.join(ALIGN_DIR, '{condition}_Rep1.tagAlign.gz'),
        path.join(ALIGN_DIR, '{condition}_Rep2.tagAlign.gz')
    output:
        path.join(ALIGN_DIR, '{condition}_Rep0.tagAlign.gz')
    shell:
        'zcat {input} | gzip -nc > {output}'

# generate pseudo-replicates
rule gen_pseudo:
    input:
        path.join(ALIGN_DIR, '{sample}.tagAlign.gz')
    output:
        path.join(ALIGN_DIR, '{sample}.pr1.tagAlign.gz'),
        path.join(ALIGN_DIR, '{sample}.pr2.tagAlign.gz')
    params:
        prefix = path.join(ALIGN_DIR, '{sample}.pseudoreps')
    run:
        commands = [
            'nlines=$(zcat {input} | wc -l)',
            'nlines=$(( ($nlines + 1) / 2 ))',
            'zcat {input} | shuf --random-source {input} | split -d -l $nlines - {params.prefix}',
            'gzip -nc {params.prefix}00 > {output[0]}',
            'gzip -nc {params.prefix}01 > {output[1]}',
            'rm {params.prefix}00',
            'rm {params.prefix}01'
        ]
        command_str = '; '.join(commands)
        shell(command_str)

# generate pooled pseudo-replicates
rule gen_pool_pseudo:
    input:
        r1p1 = path.join(ALIGN_DIR, '{condition}_Rep1.pr1.tagAlign.gz'),
        r1p2 = path.join(ALIGN_DIR, '{condition}_Rep1.pr2.tagAlign.gz'),
        r2p1 = path.join(ALIGN_DIR, '{condition}_Rep2.pr1.tagAlign.gz'),
        r2p2 = path.join(ALIGN_DIR, '{condition}_Rep2.pr2.tagAlign.gz')
    output:
        pr1 = path.join(ALIGN_DIR, '{condition}_Rep0.pr1.tagAlign.gz'),
        pr2 = path.join(ALIGN_DIR, '{condition}_Rep0.pr2.tagAlign.gz')
    run:
        commands = [
            'zcat {input.r1p1} {input.r2p1} | gzip -nc > {output.pr1}',
            'zcat {input.r1p2} {input.r2p2} | gzip -nc > {output.pr2}',
        ]
        command_str = '; '.join(commands)
        shell(command_str)

# Call peaks
# -------------------------------------
rule callpeak:
    input:
        path.join(ALIGN_DIR, '{sample}.tagAlign.gz')
    output:
        path.join(PEAKS_DIR, '{sample}_control_lambda.bdg'),
        temp(path.join(PEAKS_DIR, '{sample}_peaks.narrowPeak')),
        path.join(PEAKS_DIR, '{sample}_peaks.xls'),
        path.join(PEAKS_DIR, '{sample}_summits.bed'),
        path.join(PEAKS_DIR, '{sample}_treat_pileup.bdg')
    params:
        lambda wildcards:
            ' '.join([
                '-f BED',
                '-g 2.7e9',
                '--keep-dup all',
                '--outdir {}'.format(PEAKS_DIR),
                '-n {}'.format(wildcards.sample),
                '-B',
                '--SPMR',
                '--nomodel',
                '--shift -75',
                '--extsize 150',
                '-p 0.01',
                '--call-summits'
            ])
    shell:
        # MACS v2.1.0
        'macs2 callpeak -t {input} {params}'

rule zip_narrowpeak:
    input:
        path.join(PEAKS_DIR, '{sample}_peaks.narrowPeak')
    output:
        path.join(PEAKS_DIR, '{sample}_peaks.narrowPeak.gz')
    shell:
        'sort -k 8gr,8gr {input} | awk -v OFS="\t" \'{{$4="Peak_"NR; print $0}}\' | head -n 300000 | gzip -nc > {output}'

rule bdgcmp:
    input:
        trmt = path.join(PEAKS_DIR, '{sample}_treat_pileup.bdg'),
        ctrl = path.join(PEAKS_DIR, '{sample}_control_lambda.bdg')
    output:
        temp(path.join(PEAKS_DIR, '{sample}_FE.bdg'))
    params:
        lambda wildcards:
            '--o-prefix {} -m FE'.format(path.join(PEAKS_DIR,
                                                   wildcards.sample))
    shell:
        'macs2 bdgcmp -t {input.trmt} -c {input.ctrl} {params}'

rule slop_fold:
    input:
        fe = path.join(PEAKS_DIR, '{sample}_FE.bdg'),
        chrsize = '../../External/hg38.chrom.sizes'
    output:
        temp(path.join(PEAKS_DIR, '{sample}.fc.signal.bedGraph'))
    shell:
        'bedtools slop -i {input.fe} -g {input.chrsize} -b 0 | grep -v "chrEBV" | bedClip stdin {input.chrsize} {output}'

rule signal_bigwig:
    input:
        fc = path.join(PEAKS_DIR, '{sample}.fc.signal.sorted.bedGraph'),
        chrsize = '../../External/hg38.chrom.sizes'
    output:
        path.join(PEAKS_DIR, '{sample}.fc.signal.bigWig')
    shell:
        'bedGraphToBigWig {input.fc} {input.chrsize} {output}'

rule bdgcmp_signalval:
    input:
        tag = path.join(ALIGN_DIR, '{sample}.tagAlign.gz'),
        trmt = path.join(PEAKS_DIR, '{sample}_treat_pileup.bdg'),
        ctrl = path.join(PEAKS_DIR, '{sample}_control_lambda.bdg')
    output:
        temp(path.join(PEAKS_DIR, '{sample}_ppois.bdg'))
    params:
        lambda wildcards, input:
            ' '.join([
                '--o-prefix {}'.format(path.join(PEAKS_DIR, wildcards.sample)),
                '-m ppois',
                '-S $(echo "scale=6; $(zcat {} | wc -l) / 1000000" | bc)'.format(input.tag)
            ])
    shell:
        'macs2 bdgcmp -t {input.trmt} -c {input.ctrl} {params}'

rule slop_pval:
    input:
        pp = path.join(PEAKS_DIR, '{sample}_ppois.bdg'),
        chrsize = '../../External/hg38.chrom.sizes'
    output:
        temp(path.join(PEAKS_DIR, '{sample}.pval.signal.bedGraph'))
    shell:
        'bedtools slop -i {input.pp} -g {input.chrsize} -b 0 | grep -v "chrEBV" | bedClip stdin {input.chrsize} {output}'

# Filter blacklist regions
# -------------------------------------
rule filter_blacklist:
    input:
        peaks = path.join(PEAKS_DIR, '{sample}_peaks.narrowPeak.gz'),
        blacklist = '../../External/hg38.blacklist.bed'
    output:
        path.join(PEAKS_DIR, '{sample}_peaks.filtered.narrowPeak.gz')
    run:
        commands = [
            'bedtools intersect -v -a {input.peaks} -b {input.blacklist}',
            'awk -v OFS="\\t" \'\{if ($5 > 1000) $5=1000; print $0\}\'',
            'grep -P "chr[\\dXY]|[\t]"',
            'gzip -nc > {output}'
        ]
        command_str = ' | '.join(commands)
        shell(command_str)

# Miscellaneous
# -------------------------------------
rule sort_bam:
    input:
        '{file}.bam'
    output:
        '{file}.sorted.bam',
        '{file}.sorted.bam.bai'
    shell:
        'sambamba sort {input} -o {output[0]}'

rule sort_bed:
    input:
        '{file}.{ext}'
    output:
        '{file}.sorted.{ext}'
    wildcard_constraints:
        ext = 'bed(Graph)?'
    shell:
        'sort -k1,1 -V -k2,2n {input} > {output}'
